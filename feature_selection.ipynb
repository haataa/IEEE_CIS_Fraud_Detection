{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import featuretools as ft\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from random import sample \n",
    "import pickle\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "RSEED = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Original Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_num = 476\n",
    "#df_total = pd.read_csv('./data/features%s.csv'%(feat_num))\n",
    "with open('./data/features%s.pickle'%(feat_num), 'rb') as handle:\n",
    "    df_total = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 476)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_total[df_total['isFraud'].notnull()]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 476)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sample=df_train.sample(n=200000,random_state=RSEED)\n",
    "df_train_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 474)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train = df_train_sample['isFraud']\n",
    "features_train = df_train_sample.drop(columns = ['isFraud', 'TransactionID'])\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_raw = ['ProductCD', 'card2', 'card3', 'card4', 'card5','card6',\n",
    "              'addr1','addr2','P_email','R_email','M1','M2','M3',\n",
    "              'M4','M5','M6','M7','M8','M9','DeviceType','DeviceInfo','dow','hour',\n",
    "              'Device_name','Device_version','screen_width','screen_height',\n",
    "               'P_email_suffix','R_email_suffix','id_30_OS','id_30_version',\n",
    "               'is_card_freq_Device','is_wide','is_long','is_zero','is_win8_vista',\n",
    "               'is_windows_otheros','is_card_freq_pdc','is_card_freq_addr1'] \n",
    "\n",
    "ids = [ 'id_%s'%(i) for i in range(12,39)]\n",
    "categorical_raw = categorical_raw + ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical = list(set(categorical_raw).intersection(features_train.columns))\n",
    "#features_train[categorical].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47,\n",
    "          #'is_unbalance':True\n",
    "          #'scale_pos_weight':9\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_selector(params,train_num,features_train,labels_train,categorical,verbose_eval=500):\n",
    "    train_set = lgb.Dataset(features_train.iloc[0:train_num,:], label=labels_train.values[0:train_num],\n",
    "                       categorical_feature=categorical)\n",
    "    valid_set = lgb.Dataset(features_train.iloc[train_num:,:], label=labels_train.values[train_num:],\n",
    "                       categorical_feature=categorical)\n",
    "    valid_results = {}\n",
    "    model = lgb.train(params,train_set,num_boost_round = 10000, \n",
    "                   valid_sets = [train_set, valid_set],\n",
    "                    verbose_eval= verbose_eval,\n",
    "                    early_stopping_rounds = 500,\n",
    "                    evals_result=valid_results)\n",
    "    return model,valid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_importance(model,features_train,importance=0,num_keep=None):\n",
    "    fi = pd.DataFrame({'feature': features_train.columns, \n",
    "                   'importance':model.feature_importance()})\n",
    "    fi = fi.sort_values('importance', ascending = False)\n",
    "    if num_keep != None:\n",
    "        to_drop = fi.iloc[num_keep:,:].feature\n",
    "    else:\n",
    "        to_drop = fi[fi.importance <= importance].feature\n",
    "    return to_drop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_train_selector(Nfold,features_train,labels_train,categorical):\n",
    "    splits = Nfold\n",
    "    ave_auc = 0\n",
    "    valid_results = {}\n",
    "    \n",
    "    folds = KFold(n_splits = splits,random_state=RSEED)\n",
    "    \n",
    "    for fold_num, (trn_idx, val_idx) in enumerate(folds.split(features_train.values, \n",
    "                                                          labels_train.values)):\n",
    "        print(\"Fold {}\".format(fold_num))\n",
    "        train_df, y_train_df = features_train.iloc[trn_idx], labels_train.iloc[trn_idx]\n",
    "        valid_df, y_valid_df = features_train.iloc[val_idx], labels_train.iloc[val_idx]\n",
    "    \n",
    "        trn_data = lgb.Dataset(train_df, label=y_train_df,categorical_feature=categorical)\n",
    "        val_data = lgb.Dataset(valid_df, label=y_valid_df,categorical_feature=categorical)\n",
    "    \n",
    "        \n",
    "        clf = lgb.train(params,\n",
    "                        trn_data,\n",
    "                        10000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds=500,\n",
    "                       evals_result=valid_results)\n",
    "        \n",
    "\n",
    "        pred = clf.predict(valid_df)\n",
    "        auc_score = roc_auc_score(y_valid_df, pred)\n",
    "        ave_auc += auc_score / splits\n",
    "        print( \"  auc = \", auc_score )\n",
    "    return ave_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_select_feature(Nfold,features_train,labels_train,categorical,importance=0):\n",
    "    splits = Nfold\n",
    "    ave_auc = 0\n",
    "    valid_results = {}\n",
    "    to_drop=[]\n",
    "    \n",
    "    folds = KFold(n_splits = splits,random_state=RSEED)\n",
    "    \n",
    "    for fold_num, (trn_idx, val_idx) in enumerate(folds.split(features_train.values, \n",
    "                                                          labels_train.values)):\n",
    "        print(\"Fold {}\".format(fold_num))\n",
    "        train_df, y_train_df = features_train.iloc[trn_idx], labels_train.iloc[trn_idx]\n",
    "        valid_df, y_valid_df = features_train.iloc[val_idx], labels_train.iloc[val_idx]\n",
    "    \n",
    "        trn_data = lgb.Dataset(train_df, label=y_train_df,categorical_feature=categorical)\n",
    "        val_data = lgb.Dataset(valid_df, label=y_valid_df,categorical_feature=categorical)\n",
    "    \n",
    "        \n",
    "        clf = lgb.train(params,\n",
    "                        trn_data,\n",
    "                        10000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds=500,\n",
    "                       evals_result=valid_results)\n",
    "        '''\n",
    "        drop_this_round = list(select_by_importance(clf,train_df,importance=importance))\n",
    "        print(drop_this_round)\n",
    "        \n",
    "        if fold_num == 0:\n",
    "            to_drop = drop_this_round\n",
    "        else:\n",
    "            to_drop = list(set(to_drop).intersection(drop_this_round))\n",
    "        print(to_drop)\n",
    "        '''\n",
    "        \n",
    "        permutation_importance = PermutationImportance(clf, random_state=RSEED).fit(valid_df, y_valid_df)\n",
    "        eli5.show_weights(permutation_importance, feature_names = valid_df.columns.tolist())\n",
    "        \n",
    "        pred = clf.predict(valid_df)\n",
    "        auc_score = roc_auc_score(y_valid_df, pred)\n",
    "        ave_auc += auc_score / splits\n",
    "        print( \"  auc = \", auc_score )\n",
    "    \n",
    "    return ave_auc,to_drop\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with all feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.999064\tvalid_1's auc: 0.941625\n",
      "[1000]\ttraining's auc: 0.999846\tvalid_1's auc: 0.949187\n",
      "[1500]\ttraining's auc: 0.999996\tvalid_1's auc: 0.95135\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.951886\n",
      "Early stopping, best iteration is:\n",
      "[1883]\ttraining's auc: 1\tvalid_1's auc: 0.951904\n"
     ]
    }
   ],
   "source": [
    "train_num = 160000\n",
    "categorical = list(set(categorical_raw).intersection(features_train.columns))\n",
    "model,valid_results = train_selector(params,train_num,features_train,labels_train,\n",
    "                                     categorical,verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(num_leaves=491, \n",
    "                     min_child_weight = 0.03454472573214212,\n",
    "                     feature_fraction = 0.3797454081646243,\n",
    "                     bagging_fraction = 0.4181193142567742,\n",
    "                     min_data_in_leaf = 106,\n",
    "                     objective = 'binary',\n",
    "                     max_depth = -1,\n",
    "                     learning_rate = 0.006883242363721497,\n",
    "                     boosting_type = \"gbdt\",\n",
    "                     bagging_seed = 11,\n",
    "                     metric = 'auc',\n",
    "                     verbosity = -1,\n",
    "                     reg_alpha = 0.3899927210061127,\n",
    "                     reg_lambda = 0.6485237330340494,\n",
    "                     random_state = 47,\n",
    "                     n_estimators=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\tvalid_0's auc: 0.93566\n",
      "[1000]\tvalid_0's auc: 0.947201\n",
      "[1500]\tvalid_0's auc: 0.949597\n",
      "[2000]\tvalid_0's auc: 0.950041\n",
      "[2500]\tvalid_0's auc: 0.950049\n",
      "Early stopping, best iteration is:\n",
      "[2173]\tvalid_0's auc: 0.950116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.4181193142567742, bagging_seed=11,\n",
       "               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               feature_fraction=0.3797454081646243, importance_type='split',\n",
       "               learning_rate=0.006883242363721497, max_depth=-1, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=0.03454472573214212,\n",
       "               min_data_in_leaf=106, min_split_gain=0.0, n_estimators=10000,\n",
       "               n_jobs=-1, num_leaves=491, objective='binary', random_state=47,\n",
       "               reg_alpha=0.3899927210061127, reg_lambda=0.6485237330340494,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0, verbosity=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(features_train.iloc[0:160000], \n",
    "        labels_train.iloc[0:160000], \n",
    "        eval_metric=\"auc\",\n",
    "        verbose=500,\n",
    "        early_stopping_rounds=500,\n",
    "        eval_set=[(features_train.iloc[160000:], \n",
    "                   labels_train.iloc[160000:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = features_train.iloc[160000:]['card1'].copy()\n",
    "features_train.iloc[160000:]['card1'] = np.random.permutation(features_train.iloc[160000:]['card1'])\n",
    "pred = clf.predict(features_train.iloc[160000:])\n",
    "m = roc_auc_score(labels_train.iloc[160000:], pred)\n",
    "features_train.iloc[160000:]['card1'] = save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7314434685296523"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(features_train.iloc[160000:])\n",
    "m = roc_auc_score(labels_train.iloc[160000:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7495375876258439"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0d864719e2ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m perm = PermutationImportance(clf, random_state=RSEED).fit(features_train.iloc[160000:], \n\u001b[0;32m----> 2\u001b[0;31m                                                             labels_train.iloc[160000:])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prefit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "perm = PermutationImportance(clf, random_state=RSEED).fit(features_train.iloc[160000:], \n",
    "                                                            labels_train.iloc[160000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.999126\tvalid_1's auc: 0.936633\n",
      "[1000]\ttraining's auc: 0.999881\tvalid_1's auc: 0.944855\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.947841\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.948784\n",
      "Early stopping, best iteration is:\n",
      "[1596]\ttraining's auc: 1\tvalid_1's auc: 0.948164\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <lightgbm.basic.Booster object at 0x7fd8503b7eb8> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f239e2e5a89a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mave_auc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold_select_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-0933745cf358>\u001b[0m in \u001b[0;36mfold_select_feature\u001b[0;34m(Nfold, features_train, labels_train, categorical, importance)\u001b[0m\n\u001b[1;32m     35\u001b[0m         '''\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpermutation_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation_importance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpandas_available\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0;32m--> 270\u001b[0;31m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <lightgbm.basic.Booster object at 0x7fd8503b7eb8> was passed"
     ]
    }
   ],
   "source": [
    "categorical = list(set(categorical_raw).intersection(features_train.columns))\n",
    "ave_auc,to_drop = fold_select_feature(3,features_train,labels_train,categorical,importance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9455477910153023"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use is inbalanced parameter\n",
    "ave_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9457859715571262"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with all categorical featues\n",
    "ave_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection by Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_drop = list(select_by_importance(model,features_train,importance=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.996587\tvalid_1's auc: 0.936155\n",
      "[1000]\ttraining's auc: 0.999949\tvalid_1's auc: 0.945761\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.947914\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.948657\n",
      "Early stopping, best iteration is:\n",
      "[1621]\ttraining's auc: 1\tvalid_1's auc: 0.94815\n",
      "  auc =  0.9481503217222406\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.997138\tvalid_1's auc: 0.932873\n",
      "[1000]\ttraining's auc: 0.999963\tvalid_1's auc: 0.942249\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.944271\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.944686\n",
      "Early stopping, best iteration is:\n",
      "[1708]\ttraining's auc: 1\tvalid_1's auc: 0.944508\n",
      "  auc =  0.9445077717249518\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.996583\tvalid_1's auc: 0.933441\n",
      "[1000]\ttraining's auc: 0.999947\tvalid_1's auc: 0.942028\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.944093\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.944725\n",
      "Early stopping, best iteration is:\n",
      "[1692]\ttraining's auc: 1\tvalid_1's auc: 0.944436\n",
      "  auc =  0.9444363573760468\n"
     ]
    }
   ],
   "source": [
    "features_train_temp = features_train.drop(to_drop,axis=1)\n",
    "categorical_temp = list(set(categorical_raw).intersection(features_train_temp.columns))\n",
    "ave_auc = fold_train_selector(3,features_train_temp,labels_train,categorical_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456981502744131"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/feat476_rm_importance0.pickle', 'wb') as handle:\n",
    "    pickle.dump(to_drop, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Eliminate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.953302\n",
      "Early stopping, best iteration is:\n",
      "[1729]\ttraining's auc: 1\tvalid_1's auc: 0.953183\n",
      "remove Device_name improve auc from 0.9531365218167643 to 0.9534075096476156 this feature is endanger\n",
      "id_26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952548\n",
      "Early stopping, best iteration is:\n",
      "[1722]\ttraining's auc: 1\tvalid_1's auc: 0.952363\n",
      "P_email\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952819\n",
      "Early stopping, best iteration is:\n",
      "[1808]\ttraining's auc: 1\tvalid_1's auc: 0.952699\n",
      "P_email_suffix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952628\n",
      "Early stopping, best iteration is:\n",
      "[1765]\ttraining's auc: 1\tvalid_1's auc: 0.952487\n",
      "M9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.953003\n",
      "Early stopping, best iteration is:\n",
      "[1734]\ttraining's auc: 1\tvalid_1's auc: 0.952798\n",
      "card5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952742\n",
      "Early stopping, best iteration is:\n",
      "[1735]\ttraining's auc: 1\tvalid_1's auc: 0.952533\n",
      "Device_version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952814\n",
      "Early stopping, best iteration is:\n",
      "[1821]\ttraining's auc: 1\tvalid_1's auc: 0.952676\n",
      "id_22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.953038\n",
      "Early stopping, best iteration is:\n",
      "[1741]\ttraining's auc: 1\tvalid_1's auc: 0.95305\n",
      "M6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.9523\n",
      "Early stopping, best iteration is:\n",
      "[1766]\ttraining's auc: 1\tvalid_1's auc: 0.952148\n",
      "is_zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.953066\n",
      "Early stopping, best iteration is:\n",
      "[1714]\ttraining's auc: 1\tvalid_1's auc: 0.95285\n",
      "id_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952969\n",
      "Early stopping, best iteration is:\n",
      "[1783]\ttraining's auc: 1\tvalid_1's auc: 0.952908\n",
      "id_24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952548\n",
      "Early stopping, best iteration is:\n",
      "[1722]\ttraining's auc: 1\tvalid_1's auc: 0.952363\n",
      "id_30_OS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.95285\n",
      "Early stopping, best iteration is:\n",
      "[1704]\ttraining's auc: 1\tvalid_1's auc: 0.952689\n",
      "id_23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952923\n",
      "Early stopping, best iteration is:\n",
      "[1737]\ttraining's auc: 1\tvalid_1's auc: 0.952674\n",
      "M4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952626\n",
      "Early stopping, best iteration is:\n",
      "[1716]\ttraining's auc: 1\tvalid_1's auc: 0.952453\n",
      "dow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.953519\n",
      "Early stopping, best iteration is:\n",
      "[1720]\ttraining's auc: 1\tvalid_1's auc: 0.953327\n",
      "remove dow improve auc from 0.9534075096476156 to 0.9535437865440888 this feature is endanger\n",
      "R_email_suffix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952952\n",
      "Early stopping, best iteration is:\n",
      "[1740]\ttraining's auc: 1\tvalid_1's auc: 0.952781\n",
      "addr1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.949491\n",
      "Early stopping, best iteration is:\n",
      "[1799]\ttraining's auc: 1\tvalid_1's auc: 0.949389\n",
      "id_37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952834\n",
      "Early stopping, best iteration is:\n",
      "[1756]\ttraining's auc: 1\tvalid_1's auc: 0.952819\n",
      "id_36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.953034\n",
      "Early stopping, best iteration is:\n",
      "[1765]\ttraining's auc: 1\tvalid_1's auc: 0.952757\n",
      "is_card_freq_pdc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952795\n",
      "Early stopping, best iteration is:\n",
      "[1731]\ttraining's auc: 1\tvalid_1's auc: 0.952635\n",
      "M3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952631\n",
      "Early stopping, best iteration is:\n",
      "[1742]\ttraining's auc: 1\tvalid_1's auc: 0.952338\n",
      "id_34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952993\n",
      "Early stopping, best iteration is:\n",
      "[1705]\ttraining's auc: 1\tvalid_1's auc: 0.952857\n",
      "card2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.951441\n",
      "Early stopping, best iteration is:\n",
      "[1843]\ttraining's auc: 1\tvalid_1's auc: 0.951285\n",
      "M5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952769\n",
      "Early stopping, best iteration is:\n",
      "[1757]\ttraining's auc: 1\tvalid_1's auc: 0.952626\n",
      "M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.952821\n",
      "Early stopping, best iteration is:\n",
      "[1826]\ttraining's auc: 1\tvalid_1's auc: 0.952705\n",
      "M8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.953178\n",
      "Early stopping, best iteration is:\n",
      "[1741]\ttraining's auc: 1\tvalid_1's auc: 0.953064\n",
      "is_windows_otheros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinpwa/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1247: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n"
     ]
    }
   ],
   "source": [
    "best = 0.9531365218167643\n",
    "rm_col = ''\n",
    "for col in categorical:\n",
    "    print(col)\n",
    "    features_train_temp = features_train.drop(col,axis=1)\n",
    "    categorical_temp = list(set(categorical_raw).intersection(features_train_temp.columns))\n",
    "    model_temp,valid_results = train_selector(params,train_num,features_train_temp,labels_train,categorical_temp,verbose_eval=2000)\n",
    "    pfm = max(valid_results['valid_1']['auc'])\n",
    "    if pfm > best:\n",
    "        print('remove %s improve auc from %s to %s this feature is endanger'%(col,best,pfm))\n",
    "        best = pfm\n",
    "        rm_col = col\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ProductCD'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
